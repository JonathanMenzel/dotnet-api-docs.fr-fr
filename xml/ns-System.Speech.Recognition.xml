<Namespace Name="System.Speech.Recognition">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="be08311c812e33ac449fae40c2d2494af9dc7fe5" />
    <Meta Name="ms.sourcegitcommit" Value="434f60616a9793fa8436744549fc856e94f7a648" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="fr-FR" />
    <Meta Name="ms.lasthandoff" Value="08/24/2018" />
    <Meta Name="ms.locfileid" Value="30735973" />
  </Metadata>
  <Docs>
    <summary>L'espace de noms <see cref="N:System.Speech.Recognition" /> contient les types de technologie Windows Desktop Speech pour l'implémentation de la reconnaissance vocale.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Le logiciel de technologie vocale du bureau Windows offre une infrastructure de reconnaissance vocale élémentaire qui numérise les signaux acoustiques et récupère des mots et des éléments de la reconnaissance vocale à partir de l’entrée audio.  
  
 Les applications utilisent le <xref:System.Speech.Recognition> espace de noms pour accéder à et étendre cette technologie de reconnaissance vocale élémentaire en définissant des algorithmes permettant d’identifier et d’agir sur les expressions spécifiques ou des modèles de word et en gérant le comportement d’exécution de cette reconnaissance vocale infrastructure.  
  
 **Créer les grammaires**  
  
 Vous créez des grammaires, qui consistent en un ensemble de règles ou de contraintes, pour définir des mots et expressions reconnaisse votre application en tant qu’entrée explicite. À l’aide d’un constructeur pour le <xref:System.Speech.Recognition.Grammar> (classe), vous pouvez créer un objet de grammaire lors de l’exécution à partir de <xref:System.Speech.Recognition.GrammarBuilder> ou <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> instances, ou à partir d’un fichier, une chaîne ou un flux qui contient une définition d’une syntaxe.  
  
 À l’aide de la <xref:System.Speech.Recognition.GrammarBuilder> et <xref:System.Speech.Recognition.Choices> classes, vous pouvez créer par programmation les grammaires de complexité faible à moyenne qui peut être utilisée pour effectuer la reconnaissance pour de nombreux scénarios. Pour créer des grammaires par programme qui se conforment à la [1.0 Speech Recognition Grammar Specification (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) et tirer parti de la souplesse de création de SRGS, utilisez les types de la <xref:System.Speech.Recognition.SrgsGrammar> espace de noms. Vous pouvez également créer des grammaires SRGS d’au format XML à l’aide de n’importe quel texte éditeur et permet de créer le résultat <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , ou <xref:System.Speech.Recognition.Grammar> objets.  
  
 En outre, la <xref:System.Speech.Recognition.DictationGrammar> classe fournit une syntaxe de cas spéciaux pour prendre en charge un modèle de dictée conventionnel.  
  
 Consultez [grammaires créer](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd) dans le [Guide de programmation de reconnaissance vocale de système pour le .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) pour plus d’informations et des exemples.  
  
 **Gérer les moteurs de reconnaissance vocale**  
  
 Instances de <xref:System.Speech.Recognition.SpeechRecognizer> et <xref:System.Speech.Recognition.SpeechRecognitionEngine> fourni avec <xref:System.Speech.Recognition.Grammar> objets fournissent l’accès principal pour les moteurs de reconnaissance vocale de la technologie vocale du bureau Windows.  
  
 Vous pouvez utiliser la <xref:System.Speech.Recognition.SpeechRecognizer> classe pour créer des applications qui utilisent la technologie de reconnaissance vocale fournie par Windows, vous pouvez configurer par le biais de client le **le panneau de configuration**. De telles applications acceptent les entrées via un mécanisme d’entrée audio par défaut de l’ordinateur.  
  
 Pour mieux contrôler la configuration et le type de moteur de reconnaissance, générer une application à l’aide de <xref:System.Speech.Recognition.SpeechRecognitionEngine>, qui s’exécute in-process. À l’aide de la <xref:System.Speech.Recognition.SpeechRecognitionEngine> (classe), vous pouvez sélectionner également dynamiquement d’entrée à partir d’appareils, des fichiers ou des flux audio.  
  
 Consultez [initialiser et gérer un moteur de reconnaissance vocale](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) dans le [Guide de programmation de reconnaissance vocale de système pour le .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) pour plus d’informations.  
  
 **Répondre aux événements**  
  
 <xref:System.Speech.Recognition.SpeechRecognizer> et <xref:System.Speech.Recognition.SpeechRecognitionEngine> objets génèrent des événements en réponse à l’entrée audio pour le moteur de reconnaissance vocale. Le `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` sont déclenchés en réponse aux modifications dans le signal entrant. Le `SpeechDetected` événement est déclenché lorsque le moteur de reconnaissance vocale identifie audio entrant comme vocale. Le moteur de reconnaissance vocale déclenche le `SpeechRecognized` événement lorsqu’il correspond à l’entrée vocale à un de ses grammaires chargées et déclenche le `SpeechRecognitionRejected` lorsque la saisie vocale ne correspond pas à un des ses grammaires chargées.  
  
 Les autres types d’événements incluent le `LoadGrammarCompleted` l’événement qui a un moteur de reconnaissance vocale déclenche lorsqu’il a chargé une grammaire. Le <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> est exclusif à la <xref:System.Speech.Recognition.SpeechRecognizer> (classe), ce qui déclenche l’événement lorsque l’état de la reconnaissance vocale Windows change.  
  
 Vous pouvez vous inscrire pour être informé des événements qui déclenche le moteur de reconnaissance vocale et de créer des gestionnaires à l’aide de la `EventsArgs` classes associées à chacun de ces événements à programmer le comportement de votre application lorsqu’un événement est déclenché.  
  
 Consultez [à l’aide des événements de reconnaissance vocale](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482) dans le [Guide de programmation de reconnaissance vocale de système pour le .NET Framework 4.0](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043) pour plus d’informations.  
  
 ]]></format>
    </remarks>
    <altmember cref="N:System.Speech.AudioFormat" />
    <altmember cref="N:System.Speech.Recognition.SrgsGrammar" />
    <altmember cref="N:System.Speech.Synthesis" />
    <altmember cref="N:System.Speech.Synthesis.TtsEngine" />
  </Docs>
</Namespace>