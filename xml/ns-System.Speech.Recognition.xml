<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="ns-System.Speech.Recognition.xml" source-language="en-US" target-language="fr-FR">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-efd8310" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5a83ea4b-dd12-480b-bfc8-267272ef1864be08311c812e33ac449fae40c2d2494af9dc7fe5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">be08311c812e33ac449fae40c2d2494af9dc7fe5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">df6cf590aa3087f6c7c202712eee781c6a3c8f96</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/10/2018</xliffext:ms.lasthandoff>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.</source>
          <target state="translated">L'espace de noms <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> contient les types de technologie Windows Desktop Speech pour l'implémentation de la reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.</source>
          <target state="translated">Le logiciel de la technologie de reconnaissance vocale Windows Desktop offre une infrastructure de reconnaissance vocale élémentaire qui numérise signaux acoustiques et récupère des mots et des éléments de reconnaissance vocale à partir de l’entrée audio.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.</source>
          <target state="translated">Les applications utilisent le <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> espace de noms d’accès et d’étendre cette technologie de reconnaissance vocale base en définissant des algorithmes pour identifier et agissant sur des expressions spécifiques ou des modèles de word et en gérant le comportement d’exécution de cette voix infrastructure.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Grammars<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Créer des grammaires<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.</source>
          <target state="translated">Vous créez des grammaires qui se composent d’un ensemble de règles ou de contraintes, à définir des mots et expressions qui reconnaît votre application en tant qu’entrée explicite.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using a constructor for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.</source>
          <target state="translated">À l’aide d’un constructeur pour le <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> (classe), vous pouvez créer un objet de grammaire lors de l’exécution à partir de <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> ou <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, ou à partir d’un fichier, une chaîne ou un flux de données qui contient une définition d’une grammaire.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.</source>
          <target state="translated">À l’aide de la <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> et <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, vous pouvez créer par programme des grammaires de complexité faible à moyenne qui peut être utilisée pour effectuer une reconnaissance pour de nombreux scénarios courants.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create grammars programmatically that conform to the <bpt id="p1">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.</source>
          <target state="translated">Pour créer des grammaires par programme qui se conforment à la <bpt id="p1">[</bpt>vocale reconnaissance grammaire spécification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> et tirer parti de la souplesse de création de SRGS, utilisez les types de le <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> espace de noms.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Vous pouvez également créer les grammaires SRGS d’au format XML à l’aide de n’importe quel texte éditeur et permet de créer le résultat <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , ou <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>In addition, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.</source>
          <target state="translated">En outre, la <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> classe fournit une grammaire spécial pour prendre en charge un modèle dictée classique.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Create Grammars<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
          <target state="translated">Consultez <bpt id="p1">[</bpt>créer les grammaires<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> dans les <bpt id="p2">[</bpt>Guide de programmation système vocale pour le .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> pour plus d’informations et des exemples.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Manage Speech Recognition Engines<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Gérer les moteurs de reconnaissance vocale<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instances of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.</source>
          <target state="translated">Instances de <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> et <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> fourni avec <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets fournissent l’accès principal pour la reconnaissance vocale de la technologie de reconnaissance vocale de bureau Windows.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id="p1">**</bpt>Control Panel<ept id="p1">**</ept>.</source>
          <target state="translated">Vous pouvez utiliser la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> classe pour créer des applications qui utilisent la technologie de reconnaissance vocale fournie par Windows, vous pouvez configurer via client le <bpt id="p1">**</bpt>le panneau de configuration<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>Such applications accept input through a computer's default audio input mechanism.</source>
          <target state="translated">De telles applications acceptent l’entrée via le mécanisme d’entrée audio par défaut de l’ordinateur.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more control over the configuration and type of recognition engine, build an application using <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.</source>
          <target state="translated">Pour mieux contrôler la configuration et le type de moteur de reconnaissance, générer une application à l’aide de <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, qui s’exécute dans le processus.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.</source>
          <target state="translated">À l’aide de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> (classe), vous pouvez sélectionner également dynamiquement d’entrée à partir des appareils, des fichiers ou des flux audio.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Consultez <bpt id="p1">[</bpt>initialiser et gérer un moteur de reconnaissance vocale<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> dans les <bpt id="p2">[</bpt>Guide de programmation système vocale pour le .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> pour plus d’informations.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Répondre aux événements<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> et <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objets génèrent des événements en réponse à l’entrée audio pour le moteur de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.</source>
          <target state="translated">Le <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> sont déclenchés en réponse aux modifications dans le signal d’entrée.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.</source>
          <target state="translated">Le <ph id="ph1">`SpeechDetected`</ph> événement est déclenché lorsque le moteur de reconnaissance vocale identifie son entrant en tant que la reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engine raises the <ph id="ph1">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id="ph2">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.</source>
          <target state="translated">Le moteur de reconnaissance vocale déclenche le <ph id="ph1">`SpeechRecognized`</ph> événement lorsqu’il correspond à entrée vocale sur l’un des ses grammaires chargées et déclenche le <ph id="ph2">`SpeechRecognitionRejected`</ph> lorsque la saisie vocale ne correspond pas à un de ses grammaires chargées.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>Other types of events include the <ph id="ph1">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.</source>
          <target state="translated">Incluent d’autres types d’événements le <ph id="ph1">`LoadGrammarCompleted`</ph> l’événement qui se déclenche de reconnaissance vocale lorsqu’il a chargé une grammaire.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> est exclusif à la <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> (classe), laquelle déclenche l’événement lorsque l’état de la reconnaissance vocale Windows change.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id="ph1">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.</source>
          <target state="translated">Vous pouvez vous inscrire pour être informé des événements que le moteur de reconnaissance vocale déclenche et créer des gestionnaires à l’aide de la <ph id="ph1">`EventsArgs`</ph> classes associées à chacun de ces événements pour programmer le comportement de votre application quand un événement est déclenché.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Consultez <bpt id="p1">[</bpt>utilisation des événements de reconnaissance vocale<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> dans les <bpt id="p2">[</bpt>Guide de programmation système vocale pour le .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> pour plus d’informations.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>