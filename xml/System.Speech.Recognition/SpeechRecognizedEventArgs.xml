<Type Name="SpeechRecognizedEventArgs" FullName="System.Speech.Recognition.SpeechRecognizedEventArgs">
  <Metadata><Meta Name="ms.openlocfilehash" Value="7940e4fc991649f894d5bedfee2d8937926f8188" /><Meta Name="ms.sourcegitcommit" Value="c0c07dbd19cd7017243f9ac36915755f79bc8da6" /><Meta Name="ms.translationtype" Value="HT" /><Meta Name="ms.contentlocale" Value="fr-FR" /><Meta Name="ms.lasthandoff" Value="11/27/2018" /><Meta Name="ms.locfileid" Value="52381102" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognizedEventArgs : System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit SpeechRecognizedEventArgs extends System.Speech.Recognition.RecognitionEventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizedEventArgs&#xA;Inherits RecognitionEventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizedEventArgs : System::Speech::Recognition::RecognitionEventArgs" />
  <TypeSignature Language="F#" Value="type SpeechRecognizedEventArgs = class&#xA;    inherit RecognitionEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognitionEventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2;netframework-4.8">
      <AttributeName>System.Serializable</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Fournit des informations pour les événements <see cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />, <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> et <see cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Un `SpeechRecognized` événement est déclenché par le <xref:System.Speech.Recognition.Grammar>, <xref:System.Speech.Recognition.SpeechRecognizer> et <xref:System.Speech.Recognition.SpeechRecognitionEngine> classes.  
  
 `SpeechRecognized` événements sont générés lorsqu’un ou plusieurs des variantes à partir d’une opération de reconnaissance ont un score de confiance suffisamment élevée d’être acceptés. Pour obtenir des informations détaillées sur une expression reconnue, accédez à la <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> propriété dans le gestionnaire pour l’événement.  
  
 `SpeechRecognizedEventArgs` dérive le <xref:System.Speech.Recognition.RecognitionEventArgs> classe.  
  
   
  
## Examples  
 L’exemple suivant fait partie d’une application console qui charge une syntaxe de reconnaissance vocale et montre la saisie vocale pour le module de reconnaissance partagé, les résultats de reconnaissance associées et les événements associés déclenchés par le module de reconnaissance vocale. Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application sera également démarrer la reconnaissance vocale Windows.  
  
 Parlée entrée comme « Je veux passage de Chicago à Miami » déclenchera un <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> événement. À propos de l’expression « Piloter me de Houston à Chicago » ne déclenche pas une <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> événement.  
  
 L’exemple utilise un gestionnaire pour le <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> événement pour afficher correctement reconnu des expressions et la sémantique qu’ils contiennent dans la console.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
    <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
  </Docs>
  <Members />
</Type>