<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognizer.xml" source-language="en-US" target-language="fr-FR">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5bc77257cd77c3fc2c078698df4cc6e968d3bf09a.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc77257cd77c3fc2c078698df4cc6e968d3bf09a</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
          <target state="translated">Permet d'accéder au service de reconnaissance vocale partagé disponible sur le Bureau Windows.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
          <target state="translated">Les applications utilisent le module de reconnaissance partagé pour accéder à la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object to add to the Windows speech user experience.</source>
          <target state="translated">Utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objet à ajouter à l’expérience utilisateur de reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This class provides control over various aspects of the speech recognition process:</source>
          <target state="translated">Cette classe fournit un contrôle sur les différents aspects du processus de reconnaissance vocale :</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</source>
          <target state="translated">Pour gérer les grammaires de reconnaissance vocale, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, et <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To get information about current speech recognition operations, subscribe to the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>’s <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">Pour obtenir plus d’informations sur la reconnaissance vocale actuel opérations de reconnaissance, s’abonner à la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>de <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, et <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événements.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To view or modify the number of alternate results the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">Pour afficher ou modifier le nombre d’autres résultats retournés par le module de reconnaissance, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Le module de reconnaissance retourne les résultats de la reconnaissance dans un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> objet.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To access or monitor the state of the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> properties and the <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, and <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
          <target state="translated">Pour accéder ou surveiller l’état du module de reconnaissance partagé, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, et <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> propriétés et le <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, et <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> événements.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Pour synchroniser les modifications apportées au module de reconnaissance, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">Le module de reconnaissance partagé utilise plusieurs threads pour effectuer des tâches.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate input to the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Pour émuler l’entrée dans le module de reconnaissance partagé, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> et <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> méthodes.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">La configuration de la reconnaissance vocale Windows est gérée par l’utilisation de la <bpt id="p1">**</bpt>propriétés de reconnaissance vocale<ept id="p1">**</ept> boîte de dialogue de la <bpt id="p2">**</bpt>le panneau de configuration<ept id="p2">**</ept>.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
          <target state="translated">Cette interface est utilisée pour sélectionner le moteur de reconnaissance vocale par défaut, la langue, le périphérique d’entrée audio et le comportement de mise en veille de la reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objects.</source>
          <target state="translated">Si la configuration de la reconnaissance vocale Windows est modifiée alors que l’application est en cours d’exécution, (par exemple, si la reconnaissance vocale est désactivée ou la modification de la langue d’entrée), la modification affecte toutes les <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objets.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class.</source>
          <target state="translated">Pour créer un module de reconnaissance vocale de dans le processus qui est indépendante de la reconnaissance vocale Windows, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> classe.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">Appelez toujours <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> avant de libérer votre dernière référence au module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">Sinon, les ressources qu’il utilise ne seront pas libérées tant que le garbage collector n’appelle l’objet de module de reconnaissance <ph id="ph1">`Finalize`</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console qui charge une grammaire de reconnaissance vocale et illustre une entrée émulée asynchrone, les résultats de la reconnaissance associés et les événements associés déclenchés par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> retourne toujours null.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> class.</source>
          <target state="translated">Initialise une nouvelle instance de la classe <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object maintains a separate set of speech recognition grammars.</source>
          <target state="translated">Chaque <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objet conserve un ensemble distinct de grammaires de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console qui charge une grammaire de reconnaissance vocale et illustre une entrée émulée asynchrone, les résultats de la reconnaissance associés et les événements associés déclenchés par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> retourne toujours null.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
          <target state="translated">Obtient le format de l'audio reçu par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>The audio input format for the speech recognizer, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the input to the recognizer is not configured.</source>
          <target state="translated">Format d'entrée audio pour le module de reconnaissance vocale ou <ph id="ph1">&lt;see langword="null" /&gt;</ph> si l'entrée fournie au module de reconnaissance n'est pas configurée.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
          <target state="translated">Obtient le niveau de l'audio reçu par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">Niveau sonore de l'entrée fournie au module de reconnaissance vocale, compris entre 0 et 100.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance partagé indique le niveau de son entrée audio.</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The recognizer raises this event multiple times per second.</source>
          <target state="translated">Le module de reconnaissance déclenche cet événement plusieurs fois par seconde.</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">L’ordinateur sur lequel l’application est en cours d’exécution dépend de la fréquence à laquelle l’événement est déclenché.</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">Pour obtenir le niveau audio au moment de l’événement, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> propriété associé au <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">Pour obtenir le niveau de l’entrée dans le module de reconnaissance audio actuel, utilisez le module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">`AudioLevelUpdated`</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">`AudioLevelUpdated`</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object.</source>
          <target state="translated">L’exemple suivant ajoute un gestionnaire pour le <ph id="ph1">`AudioLevelUpdated`</ph> événement à un <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objet.</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">Le gestionnaire génère le nouveau niveau audio à la console.</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
          <target state="translated">Obtient la position actuelle dans le flux audio généré par le périphérique qui gère les entrées pour le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
          <target state="translated">Position actuelle du flux d'entrée audio du module de reconnaissance vocale via lequel a été reçue l'entrée.</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
          <target state="translated">Le module de reconnaissance partagé reçoit des entrées pendant l’exécution de la reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">Le <ph id="ph1">`AudioPosition`</ph> propriété fait référence à la position du périphérique d’entrée dans son flux audio généré.</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position in processing audio input.</source>
          <target state="translated">En revanche, le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> propriété fait référence à la position du module de reconnaissance lors du traitement de l’entrée audio.</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Ces positions peuvent être différentes.</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Par exemple, si le module de reconnaissance a reçu d’entrée pour lesquels il n’a pas encore généré un résultat de reconnaissance alors la valeur de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> propriété est inférieure à la valeur de la <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">Dans l’exemple suivant, le module de reconnaissance vocale partagé utilise une grammaire dictée pour correspondre à une entrée vocale.</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">Un gestionnaire pour le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> événement est écrit dans la console le <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, et <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> lorsque le module de reconnaissance vocale détecte vocale sur son entrée.</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance rencontre un problème dans le signal audio.</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">Pour obtenir le problème s’est produit, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> propriété associé au <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">`AudioSignalProblemOccurred`</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event.</source>
          <target state="translated">L’exemple suivant définit un gestionnaire d’événements qui rassemble des informations sur une <ph id="ph1">`AudioSignalProblemOccurred`</ph> événement.</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
          <target state="translated">Obtient l'état de l'audio reçu par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">État de l'entrée audio dans le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
          <target state="translated">Se produit lors du changement de l'état de l'audio reçu par le module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Pour obtenir l’état audio au moment de l’événement, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> propriété associé au <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">Pour obtenir l’état audio actuel de l’entrée dans le module de reconnaissance, utilisez le module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">Pour plus d’informations sur l’état audio, consultez la <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> énumération.</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">`AudioStateChanged`</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">`AudioStateChanged`</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> to the console each time it changes using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">L’exemple suivant utilise un gestionnaire pour le <ph id="ph1">`AudioStateChanged`</ph> événement à écrire le module de reconnaissance de nouveau <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> à la console chaque fois qu’il les modifications à l’aide d’un membre de la <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> énumération.</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Supprime l'objet <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Supprime l'objet <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> pour libérer les ressources managées et non managées ; <ph id="ph2">&lt;see langword="false" /&gt;</ph> pour ne libérer que les ressources non managées.</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated">Supprime l’objet <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> et libère les ressources utilisées pendant la session.</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Émule l'entrée dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale synchrone.</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Ces méthodes ignorer l’entrée audio du système.</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Cela peut être utile lorsque vous testez ou débogage d’une application ou la grammaire.</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then these methods return <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis ces méthodes retournent <ph id="ph1">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Le module de reconnaissance partagé déclenche le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, et <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événements comme si l’opération de reconnaissance n’est pas émulée.</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Le module de reconnaissance ignore les nouvelles lignes et les espaces superflus et traite des signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> objet généré par le module de reconnaissance partagé en réponse à l’entrée émulée a la valeur <ph id="ph2">`null`</ph> pour son <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">Pour émuler la reconnaissance asynchrone, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Entrée de l'opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">Émule l'entrée d'une expression dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale synchrone.</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Résultat de la reconnaissance pour l’opération de reconnaissance ou <ph id="ph1">&lt;see langword="null" /&gt;</ph>, si l’opération n’est pas réussie ou si la reconnaissance vocale Windows est dans l’état de <bpt id="p1">**</bpt>veille<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Les identificateurs sont fournis avec Vista et Windows 7 ignorent la casse et la largeur de caractère lors de l’application des règles grammaticales de l’expression d’entrée.</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Pour plus d’informations sur ce type de comparaison, consultez le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> valeurs d’énumération <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> et <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Les modules de reconnaissance également ignore les nouvelles lignes et les espaces superflus et traitent des signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</source>
          <target state="translated">L’exemple suivant charge une grammaire exemple au module de reconnaissance partagé et émule entrée dans le module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> always returns null.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> retourne toujours null.</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Un tableau d'unités de mot qui contient l'entrée pour l'opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinaison d'opérations de bits des valeurs d'énumération qui décrivent le type de comparaison à utiliser pour la reconnaissance émulée.</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Émule l'entrée de mots spécifiques dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale synchrone, et spécifie comment le module de reconnaissance gère la comparaison Unicode entre les mots et les grammaires de la reconnaissance vocale chargées.</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Résultat de la reconnaissance pour l’opération de reconnaissance ou <ph id="ph1">&lt;see langword="null" /&gt;</ph>, si l’opération n’est pas réussie ou si la reconnaissance vocale Windows est dans l’état de <bpt id="p1">**</bpt>veille<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Cette méthode crée un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> de l’objet à l’aide des informations fournies dans le <ph id="ph2">`wordUnits`</ph> paramètre.</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Le module de reconnaissance utilise le <ph id="ph1">`compareOptions`</ph> lorsqu’il applique des règles de grammaire pour l’expression d’entrée.</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Les identificateurs sont fournis avec Vista et Windows 7 ignorent la casse si le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> ou <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valeur est présente.</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Les identificateurs de toujours ignorent la largeur des caractères et jamais ignorer le type Kana.</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Les modules de reconnaissance également ignore les nouvelles lignes et les espaces superflus et traite les signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Pour plus d’informations sur la largeur des caractères et le type Kana, consultez le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> énumération.</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Expression d'entrée de l'opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinaison d'opérations de bits des valeurs d'énumération qui décrivent le type de comparaison à utiliser pour la reconnaissance émulée.</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Émule l'entrée d'une expression dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale synchrone, et spécifie comment le module de reconnaissance gère la comparaison Unicode entre l'expression et les grammaires de la reconnaissance vocale chargées.</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">Résultat de la reconnaissance pour l’opération de reconnaissance ou <ph id="ph1">&lt;see langword="null" /&gt;</ph>, si l’opération n’est pas réussie ou si la reconnaissance vocale Windows est dans l’état de <bpt id="p1">**</bpt>veille<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Le module de reconnaissance utilise le <ph id="ph1">`compareOptions`</ph> lorsqu’il applique des règles de grammaire pour l’expression d’entrée.</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Les identificateurs sont fournis avec Vista et Windows 7 ignorent la casse si le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> ou <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valeur est présente.</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Les identificateurs de toujours ignorent la largeur des caractères et jamais ignorer le type Kana.</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Les modules de reconnaissance également ignore les nouvelles lignes et les espaces superflus et traite les signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Pour plus d’informations sur la largeur des caractères et le type Kana, consultez le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> énumération.</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Émule l'entrée dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale asynchrone.</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">Ces méthodes ignorer l’entrée audio du système.</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">Cela peut être utile lorsque vous testez ou débogage d’une application ou la grammaire.</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">Le module de reconnaissance partagé déclenche le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, et <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événements comme si l’opération de reconnaissance n’est pas émulée.</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Lorsque le module de reconnaissance termine l’opération de reconnaissance asynchrone, il déclenche le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Le module de reconnaissance ignore les nouvelles lignes et les espaces superflus et traite des signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then the shared recognizer does not process input and does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> and related events, but still raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis le module de reconnaissance partagé ne traite pas d’entrée et ne génère pas le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> et événements connexes, mais toujours déclenche le <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> objet généré par le module de reconnaissance partagé en réponse à l’entrée émulée a la valeur <ph id="ph2">`null`</ph> pour son <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">Pour émuler la reconnaissance synchrone, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">Entrée de l'opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">Émule l'entrée d'une expression dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale asynchrone.</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Les identificateurs sont fournis avec Vista et Windows 7 ignorent la casse et la largeur de caractère lors de l’application des règles grammaticales de l’expression d’entrée.</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">Pour plus d’informations sur ce type de comparaison, consultez le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> valeurs d’énumération <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> et <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">Les modules de reconnaissance également ignore les nouvelles lignes et les espaces superflus et traitent des signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console qui charge une grammaire de reconnaissance vocale et illustre une entrée émulée asynchrone, les résultats de la reconnaissance associés et les événements associés déclenchés par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> retourne toujours null.</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">Un tableau d'unités de mot qui contient l'entrée pour l'opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinaison d'opérations de bits des valeurs d'énumération qui décrivent le type de comparaison à utiliser pour la reconnaissance émulée.</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">Émule l'entrée de mots spécifiques dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale asynchrone, et spécifie comment le module de reconnaissance gère la comparaison Unicode entre les mots et les grammaires de la reconnaissance vocale chargées.</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">Cette méthode crée un <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> de l’objet à l’aide des informations fournies dans le <ph id="ph2">`wordUnits`</ph> paramètre.</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Le module de reconnaissance utilise le <ph id="ph1">`compareOptions`</ph> lorsqu’il applique des règles de grammaire pour l’expression d’entrée.</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Les identificateurs sont fournis avec Vista et Windows 7 ignorent la casse si le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> ou <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valeur est présente.</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Les identificateurs de toujours ignorent la largeur des caractères et jamais ignorer le type Kana.</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Les modules de reconnaissance également ignore les nouvelles lignes et les espaces superflus et traite les signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Pour plus d’informations sur la largeur des caractères et le type Kana, consultez le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> énumération.</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">Expression d'entrée de l'opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">Combinaison d'opérations de bits des valeurs d'énumération qui décrivent le type de comparaison à utiliser pour la reconnaissance émulée.</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">Émule l'entrée d'une expression dans le module de reconnaissance vocale partagé, en utilisant le texte au lieu de l'audio pour la reconnaissance vocale asynchrone, et spécifie comment le module de reconnaissance gère la comparaison Unicode entre l'expression et les grammaires de la reconnaissance vocale chargées.</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">Le module de reconnaissance utilise le <ph id="ph1">`compareOptions`</ph> lorsqu’il applique des règles de grammaire pour l’expression d’entrée.</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Les identificateurs sont fournis avec Vista et Windows 7 ignorent la casse si le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> ou <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> valeur est présente.</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">Les identificateurs de toujours ignorent la largeur des caractères et jamais ignorer le type Kana.</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">Les modules de reconnaissance également ignore les nouvelles lignes et les espaces superflus et traite les signes de ponctuation en tant qu’entrée littéral.</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">Pour plus d’informations sur la largeur des caractères et le type Kana, consultez le <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> énumération.</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance partagé finalise un module de reconnaissance asynchrone pour l'entrée émulée.</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">Chaque <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> méthode commence une opération asynchrone de reconnaissance.</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">Le module de reconnaissance déclenche le <ph id="ph1">`EmulateRecognizeCompleted`</ph> événement lorsqu’il finalise l’opération asynchrone.</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The asynchronous recognition operation can raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">L’opération de reconnaissance asynchrone peut déclencher la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, et <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événements.</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> événement est le dernier événement de ce type que le module de reconnaissance se déclenche pour une opération donnée.</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">`EmulateRecognizeCompleted`</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console qui charge une grammaire de reconnaissance vocale et illustre une entrée émulée asynchrone, les résultats de la reconnaissance associés et les événements associés déclenchés par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> mode, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> mode, puis <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> retourne toujours null.</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Gets or sets a value that indicates whether this <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is ready to process speech.</source>
          <target state="translated">Obtient ou définit une valeur qui indique si cet objet de <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> est prêt à procéder à la reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is performing speech recognition; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> si cet objet <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> exécute la reconnaissance vocale ; sinon, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Changes to this property do not affect other instances of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class.</source>
          <target state="translated">Modifications apportées à cette propriété n’affectent pas les autres instances de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> classe.</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>By default, the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property is <ph id="ph2">`true`</ph> for a newly instantiated instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</source>
          <target state="translated">Par défaut, la valeur de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> propriété <ph id="ph2">`true`</ph> pour une instance qui vient d’être instanciée de <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
          <target state="translated">Lorsque le module de reconnaissance est désactivé, aucun des grammaires de reconnaissance du module de reconnaissance vocale sont disponibles pour les opérations de reconnaissance.</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Setting the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Configuration du module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> propriété n’a aucun effet sur le module de reconnaissance <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> instance.</source>
          <target state="translated">Obtient une collection des objets <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> chargés dans cette instance <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>A collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that the application loaded into the current instance of the shared recognizer.</source>
          <target state="translated">Collection d'objets <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> que l'application a chargé dans l'instance actuelle du module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
          <target state="translated">Cette propriété ne retourne pas de n’importe quel vocale grammaires de reconnaissance chargées par une autre application.</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</source>
          <target state="translated">L’exemple suivant génère des informations sur la console pour chaque grammaire de reconnaissance vocale chargé dans le module de reconnaissance vocale partagé.</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Syntaxe de reconnaissance vocale à charger.</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Loads a speech recognition grammar.</source>
          <target state="translated">Charge une grammaire de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Le module de reconnaissance partagé lève une exception si la grammaire de reconnaissance vocale est déjà chargée, est en cours de chargement asynchrone ou n’a pas pu charger dans n’importe quel module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Si le module de reconnaissance est en cours d’exécution, les applications doivent utiliser <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> pour suspendre le moteur de reconnaissance vocale avant le chargement, déchargement, activer ou désactiver une grammaire.</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar asynchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">Pour charger une grammaire de reconnaissance vocale de façon asynchrone, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console qui charge une grammaire de reconnaissance vocale et illustre une entrée émulée asynchrone, les résultats de la reconnaissance associés et les événements associés déclenchés par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Si la reconnaissance vocale Windows se trouve dans le <bpt id="p1">**</bpt>couchage<ept id="p1">**</ept> d’état, puis <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> retourne toujours null.</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">Syntaxe de reconnaissance vocale à charger.</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">Charge une syntaxe de reconnaissance vocale de façon asynchrone.</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes this asynchronous operation, it raises a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">Lorsque le module de reconnaissance termine à cette opération asynchrone, il déclenche une <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">Le module de reconnaissance lève une exception si la grammaire de reconnaissance vocale est déjà chargée, est en cours de chargement asynchrone ou n’a pas pu charger dans n’importe quel module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Si le module de reconnaissance est en cours d’exécution, les applications doivent utiliser <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> pour suspendre le moteur de reconnaissance vocale avant le chargement, déchargement, activer ou désactiver une grammaire.</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Pour charger une grammaire de reconnaissance vocale de façon synchrone, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance termine le chargement asynchrone d'une syntaxe de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">Le module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> méthode initie une opération asynchrone.</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
          <target state="translated">Le module de reconnaissance déclenche le <ph id="ph1">`LoadGrammarCompleted`</ph> événement lorsqu’il termine l’opération.</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">Pour obtenir le <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> que le module de reconnaissance est chargé de l’objet, utilisez le <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> propriété associé au <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">Pour obtenir l’actuel <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets chargé le module de reconnaissance, utilisez le module de reconnaissance <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">`LoadGrammarCompleted`</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">L’exemple suivant crée un module de reconnaissance vocale partagé et il crée ensuite deux types de grammaires de reconnaissance des mots spécifiques et pour l’acceptation de dictée libre.</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">L’exemple de charge de façon asynchrone toutes les grammaires créés pour le module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">Gestionnaires pour le module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> et <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événements écrivent dans la console, le nom de la grammaire a été utilisé pour effectuer de la reconnaissance et le texte du résultat de la reconnaissance, respectivement.</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
          <target state="translated">Obtient ou définit le nombre maximal de résultats de reconnaissance retourné pour chaque opération de reconnaissance par le module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
          <target state="translated">Nombre maximum d'autres résultats que le module de reconnaissance vocale retourne pour chaque opération de reconnaissance.</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the input.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> propriété de la <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> classe contient la collection de <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objets qui représentent des autres interprétations des candidats de l’entrée.</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">La valeur par défaut <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> est 10.</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event.</source>
          <target state="translated">Obtient ou définit une valeur qui indique si le module de reconnaissance partagé suspend des opérations de reconnaissance pendant qu'une application gère un événement de <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the shared recognizer waits to process input while any application is handling the <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="true" /&gt;</ph> si le module de reconnaissance partagé attend pour traiter l'entrée alors qu'une application gère l'événement <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> ; sinon, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
          <target state="translated">Définissez cette propriété sur <ph id="ph1">`true`</ph>, si dans le <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Gestionnaire d’événements votre application a besoin pour modifier l’état du service de reconnaissance vocale ou de modifier les grammaires de reconnaissance vocale chargé ou activée avant que le service de reconnaissance vocale processus d’entrée.</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Setting the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> property to <ph id="ph2">`true`</ph> causes each <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler in every application to block the Windows speech recognition service.</source>
          <target state="translated">Définition de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> propriété <ph id="ph2">`true`</ph> , chacune <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Gestionnaire d’événements dans chaque application pour bloquer le service de reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To synchronize the changes to the shared recognizer with your application state, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Pour synchroniser les modifications apportées au module de reconnaissance partagé avec l’état de votre application, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>When <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> is <ph id="ph2">`true`</ph>, during the execution of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
          <target state="translated">Lorsque <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> est <ph id="ph2">`true`</ph>, pendant l’exécution de la <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Gestionnaire du service de reconnaissance vocale s’arrête et met en mémoire tampon nouvelle entrée audio dès qu’elle arrive.</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Once the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
          <target state="translated">Une fois la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Gestionnaire d’événements s’arrête, la reconnaissance vocale reconnaissance service reprend les démarre le traitement des informations à partir de son tampon d’entrée.</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To enable or disable the speech recognition service, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">Pour activer ou désactiver le service de reconnaissance vocale, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Obtient la position actuelle du module de reconnaissance dans l'entrée audio qu'il gère.</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">Position du module de reconnaissance dans l'entrée audio qu'il gère.</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
          <target state="translated">Le <ph id="ph1">`RecognizerAudioPosition`</ph> propriété fait référence à la position du module de reconnaissance lors du traitement de son entrée audio.</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">En revanche, le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> propriété fait référence à la position du périphérique d’entrée dans son flux audio généré.</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">Ces positions peuvent être différentes.</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">Par exemple, si le module de reconnaissance a reçu d’entrée pour lesquels il n’a pas encore généré un résultat de reconnaissance alors la valeur de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> propriété est inférieure à la valeur de la <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Gets information about the shared speech recognizer.</source>
          <target state="translated">Obtient les informations à propos du module de reconnaissance vocale partagé.</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Information about the shared speech recognizer.</source>
          <target state="translated">Informations sur le module de reconnaissance vocale partagé.</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
          <target state="translated">Cette propriété retourne des informations sur le module de reconnaissance vocale en cours d’utilisation par la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>The following example sends information about the shared recognizer to the console.</source>
          <target state="translated">L’exemple suivant envoie des informations sur le module de reconnaissance partagé dans la console.</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance s'interrompt pour synchroniser la reconnaissance et d'autres opérations.</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> before modifying its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Les applications doivent utiliser <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> pour suspendre une instance en cours d’exécution de <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> avant de modifier son <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets.</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">Par exemple, lors de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> est suspendue, vous pouvez charger, décharger, activer et désactiver <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets.</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> déclenche cet événement lorsqu’il est prêt à accepter les modifications.</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L’exemple suivant montre une application console qui charge et décharge <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets.</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">L’application utilise le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> méthode pour demander le moteur de reconnaissance vocale pour suspendre la vue de recevoir une mise à jour.</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">L’application, puis charge ou décharge une <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objet.</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">À chaque mise à jour, un gestionnaire pour <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement écrit le nom et l’état d’actuellement chargés <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets dans la console.</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Comme les grammaires sont chargées et déchargées, l’application reconnaît tout d’abord les noms d’animaux de la batterie de serveurs, puis les noms d’animaux de la batterie de serveurs et les noms de fruits, puis uniquement les noms de fruits.</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Demande que le module de reconnaissance partagé soit suspendu et mette à jour son état.</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use this method to synchronize changes to the shared recognizer.</source>
          <target state="translated">Cette méthode permet de synchroniser les modifications apportées au module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">Par exemple, si vous chargez ou déchargez une grammaire de reconnaissance vocale pendant le traitement d’entrée de module de reconnaissance, utilisez cette méthode et la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement pour synchroniser le comportement de votre application avec l’état de la reconnaissance.</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Lorsque cette méthode est appelée, le module de reconnaissance s’arrête ou effectue des opérations asynchrones et génère un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> Gestionnaire d’événements pouvez ensuite modifier l’état de la reconnaissance entre les opérations de reconnaissance.</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called:</source>
          <target state="translated">Lorsque cette méthode est appelée :</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Si le module de reconnaissance ne traite pas d’entrée, le module de reconnaissance génère immédiatement la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Si le module de reconnaissance est le traitement d’entrée se compose de latence ou de bruit de fond, le module de reconnaissance interrompt l’opération de reconnaissance et génère le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">Si le module de reconnaissance est le traitement d’entrée qui n’est pas constitué de latence ou de bruit de fond, le module de reconnaissance effectue l’opération de reconnaissance, puis génère le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">Alors que le module de reconnaissance gère le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement :</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">Le module de reconnaissance ne traite pas d’entrée et la valeur de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> propriété reste le même.</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">Le module de reconnaissance continue à collecter d’entrée et la valeur de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> propriété peut être modifiée.</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To change whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> property.</source>
          <target state="translated">Pour indiquer si le module de reconnaissance partagé suspend les opérations de reconnaissance lors d’une application gère un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événement, utilisez le <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">L’exemple suivant montre une application console qui charge et décharge <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets.</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">L’application utilise le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> méthode pour demander le moteur de reconnaissance vocale pour suspendre la vue de recevoir une mise à jour.</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">L’application, puis charge ou décharge une <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objet.</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">À chaque mise à jour, un gestionnaire pour <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement écrit le nom et l’état d’actuellement chargés <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objets dans la console.</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">Comme les grammaires sont chargées et déchargées, l’application reconnaît tout d’abord les noms d’animaux de la batterie de serveurs, puis les noms d’animaux de la batterie de serveurs et les noms de fruits, puis uniquement les noms de fruits.</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">Demande que le module de reconnaissance partagé soit suspendu et mette à jour son état.</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">Lorsque le module de reconnaissance génère le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement, le <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> propriété de la <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> est <ph id="ph4">`null`</ph>.</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Pour fournir un jeton d’utilisateur, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> ou <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Pour spécifier un décalage de position audio, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informations définies par l'utilisateur qui comporte des informations sur l'opération.</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
          <target state="translated">Demande que le module de reconnaissance partagé soit suspendu, mette à jour son état et fournisse un jeton utilisateur pour l'événement associé.</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Lorsque le module de reconnaissance génère le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement, le <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> propriété de la <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contient la valeur de le <ph id="ph4">`userToken`</ph> paramètre.</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">Pour spécifier un décalage de position audio, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">Informations définies par l'utilisateur qui comporte des informations sur l'opération.</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">Offset de la <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> actuelle pour différer la demande.</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">Demande que le module de reconnaissance partagé soit suspendu, mette à jour son état et fournisse un offset et un jeton utilisateur pour l'événement associé.</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus the value of the <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
          <target state="translated">Le module de reconnaissance ne lance pas la demande de mise à jour du module de reconnaissance jusqu'à ce que le module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> est égal à actuel <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus la valeur de le <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> paramètre.</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">Lorsque le module de reconnaissance génère le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> événement, le <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> propriété de la <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contient la valeur de le <ph id="ph4">`userToken`</ph> paramètre.</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance détecte l'entrée qu'il peut identifier comme vocale.</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The shared recognizer can raise this event in response to input.</source>
          <target state="translated">Le module de reconnaissance partagé peut déclencher cet événement en réponse à l’entrée.</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> propriété associé au <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> objet indique l’emplacement dans le flux d’entrée sur lesquels le module de reconnaissance détecté vocale.</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> properties and the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">Pour plus d’informations, consultez la <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> et <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> propriétés et le <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> et <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> méthodes.</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console pour le choix des villes d’origine et la destination d’un vol.</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">L’application reconnaît des expressions telles que « Je souhaite passage Miami à Chicago ».</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">L’exemple utilise le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> événement au rapport le <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> chaque heure de voix est détectée.</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance a identifié un mot ou des mots qui peuvent être un composant de plusieurs expressions complètes dans une syntaxe.</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
          <target state="translated">Le module de reconnaissance partagé peut déclencher cet événement lorsque l’entrée est ambigüe.</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">Par exemple, pour une grammaire de reconnaissance vocale qui prend en charge la reconnaissance de le « nouvelle de jeu. » ou « nouvelle partie », « nouvelle de jeu. » est une entrée non équivoque, et « nouvelle partie » est une entrée ambigüe.</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">L’exemple suivant reconnaît des expressions telles que « Afficher la liste d’artistes dans la catégorie jazz ».</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">L’exemple utilise le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> événement afin d’afficher les fragments de phrase incomplètes dans la console qu’elles sont reconnues.</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance accepte les entrées qui ne correspondent pas à l'une des syntaxes de reconnaissance vocale qu'il a chargé.</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
          <target state="translated">Le module de reconnaissance partagé déclenche cet événement s’il détermine qu’entrée ne correspond pas avec une confiance suffisante des grammaires de reconnaissance vocale chargé.</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> propriété de la <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contient le rejet <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> objet.</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Seuils de confiance pour le module de reconnaissance partagé, géré par <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, sont associés à un profil utilisateur et stocké dans le Registre Windows.</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Les applications ne doivent pas écrire de modifications dans le Registre pour les propriétés d’un module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">L’exemple suivant reconnaît des expressions telles que « affichent la liste d’artistes dans la catégorie jazz » ou « êtes des albums ».</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</source>
          <target state="translated">L’exemple utilise un gestionnaire pour le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> événements pour afficher une notification dans la console lorsque la voix d’entrée ne peut pas correspondre au contenu de la grammaire avec une confiance suffisante pour produire une reconnaissance réussie.</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
          <target state="translated">Se produit lorsque le module de reconnaissance reçoit l'entrée qui correspond à l'une de ses syntaxes de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
          <target state="translated">Le module de reconnaissance déclenche le <ph id="ph1">`SpeechRecognized`</ph> événement s’il détermine avec une confiance suffisante qu’entrée correspond à l’un des grammaires de reconnaissance vocale chargés et activés.</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> propriété de la <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contient accepté <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> objet.</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">Seuils de confiance pour le module de reconnaissance partagé, géré par <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, sont associés à un profil utilisateur et stocké dans le Registre Windows.</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">Les applications ne doivent pas écrire de modifications dans le Registre pour les propriétés d’un module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Lorsque le module de reconnaissance reçoit l’entrée qui correspond à une grammaire, le <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objet peut déclencher la <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Le <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> l’objet <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> événement est déclenché avant le module de reconnaissance vocale <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">L’exemple suivant fait partie d’une application console qui charge une grammaire de reconnaissance vocale et illustre l’entrée vocale pour le module de reconnaissance partagé, les résultats de la reconnaissance associés et les événements associés déclenchés par le module de reconnaissance vocale.</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Si la reconnaissance vocale Windows n’est pas en cours d’exécution, avant de démarrer cette application démarre également la reconnaissance vocale Windows.</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Parlée d’entrée, tels que « Je souhaite passage de Chicago à Miami » déclenchera un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">Est élevé, la phrase « Rendiez me de Houston à Chicago » ne déclenche pas une <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événement.</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">L’exemple utilise un gestionnaire pour le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> événement afin d’afficher correctement reconnu des expressions et la sémantique qu’ils contiennent dans la console.</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>Gets the state of a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">Obtient l'état d'un objet <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>The state of the <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated">État de l'objet <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
          <target state="translated">Cette propriété en lecture seule indique si le module de reconnaissance partagé résident dans les fenêtres se trouve dans le <ph id="ph1">`Stopped`</ph> ou <ph id="ph2">`Listening`</ph> état.</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> enumeration.</source>
          <target state="translated">Pour plus d’informations, consultez l’énumération <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
          <target state="translated">Se produit lorsque l'état d'exécution du moteur de reconnaissance de technologie vocale du Bureau Windows change.</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> state.</source>
          <target state="translated">Le module de reconnaissance partagé déclenche cet événement lorsque l’état de la reconnaissance vocale Windows le <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> ou <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> état.</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the state of the shared recognizer at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">Pour obtenir l’état du module de reconnaissance partagé au moment de l’événement, utilisez la <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> propriété associé au <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the current state of the shared recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">Pour obtenir l’état actuel de la reconnaissance partagée, utilisez le module de reconnaissance <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> propriété.</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">Lorsque vous créez un délégué pour un <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> événement, vous identifiez la méthode qui gérera l’événement.</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">Pour associer l'événement au gestionnaire d'événements, ajoutez une instance du délégué à l'événement.</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">Le gestionnaire d'événements est appelé chaque fois qu'un événement se produit, sauf si vous supprimez le délégué.</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">Pour plus d’informations sur les délégués de gestionnaires d’événements, consultez <bpt id="p1">[</bpt>événements et des délégués<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">L’exemple suivant crée un module de reconnaissance vocale partagé et il crée ensuite deux types de grammaires de reconnaissance des mots spécifiques et pour l’acceptation de dictée libre.</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">L’exemple de charge de façon asynchrone toutes les grammaires créés pour le module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event uses the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method to put Windows Recognition in "listening" mode.</source>
          <target state="translated">Un gestionnaire pour le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> événement utilise les <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> méthode permettant de placer la reconnaissance de Windows en mode « écoute ».</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
          <target state="translated">Décharge toutes les Grammaires de la Reconnaissance vocale du module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
          <target state="translated">Si le module de reconnaissance charge actuellement une grammaire de façon asynchrone, cette méthode attend jusqu'à ce que la grammaire est chargée, avant qu’il soit déchargé toutes les grammaires du module de reconnaissance.</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">Pour décharger une grammaire spécifique, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> (méthode).</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar to unload.</source>
          <target state="translated">Grammaire à décharger.</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
          <target state="translated">Décharge une Grammaire de la Reconnaissance vocale à partir du module de reconnaissance partagé.</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">Si le module de reconnaissance est en cours d’exécution, les applications doivent utiliser <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> pour suspendre le moteur de reconnaissance vocale avant le chargement, déchargement, activer ou désactiver une grammaire.</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">Pour décharger toutes les grammaires, utilisez le <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> (méthode).</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>