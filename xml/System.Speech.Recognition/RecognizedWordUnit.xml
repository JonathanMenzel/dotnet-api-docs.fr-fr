<Type Name="RecognizedWordUnit" FullName="System.Speech.Recognition.RecognizedWordUnit">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="95cbc484ad2f61d90e672b839c60865c972a6fea" />
    <Meta Name="ms.sourcegitcommit" Value="d877ae76e9e11799bf919379507239e2c4072742" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="fr-FR" />
    <Meta Name="ms.lasthandoff" Value="08/09/2018" />
    <Meta Name="ms.locfileid" Value="39988892" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizedWordUnit" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable beforefieldinit RecognizedWordUnit extends System.Object" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizedWordUnit" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizedWordUnit" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizedWordUnit" />
  <TypeSignature Language="F#" Value="type RecognizedWordUnit = class" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="netframework-3.0;netframework-3.5;netframework-4.0;netframework-4.5;netframework-4.5.1;netframework-4.5.2;netframework-4.6;netframework-4.6.1;netframework-4.6.2;netframework-4.7;netframework-4.7.1;netframework-4.7.2">
      <AttributeName>System.Diagnostics.DebuggerDisplay("Text: {Text}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Fournit l'unité atomique de discours identifié.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Tous les résultats retournés par un moteur de reconnaissance sont construites de <xref:System.Speech.Recognition.RecognizedWordUnit> objets.  
  
 Un tableau de <xref:System.Speech.Recognition.RecognizedWordUnit> objets est accessible pour toute opération de reconnaissance par le biais du <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur le <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
 En plus de fournir une mesure de certitude de reconnaissance (<xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A>) un <xref:System.Speech.Recognition.RecognizedWordUnit> instance fournit :  
  
-   Représentations sous forme de texte normalisée et exacte (ou de lexicale) pour un mot reconnu. Pour plus d'informations, consultez <xref:System.Speech.Recognition.ReplacementText>, <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> et <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>.  
  
-   Informations de prononciation à l’aide de caractères à partir d’un alphabet phonétique pris en charge, tels que l’Alphabet phonétique International (IPA) ou la valeur de téléphone universelle (UPS). Pour plus d’informations, consultez <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>.  
  
-   Mise en forme pour l’impression. Pour plus d’informations, consultez le <xref:System.Speech.Recognition.DisplayAttributes> classe et ses <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> propriété.  
  
   
  
## Examples  
 L’exemple suivant montre une routine d’utilitaire (`stringFromWordArray`) qui génère des chaînes. Les chaînes contiennent la sortie lexicale (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisé de texte (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), ou les caractères phonétiques à partir de l’Alphabet phonétique International (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). Chaînes sont mises en forme à l’aide de <xref:System.Speech.Recognition.DisplayAttributes> objets obtenus à partir de la <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> propriété à partir d’un <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> de <xref:System.Speech.Recognition.RecognizedWordUnit> objets. Le <xref:System.Speech.Recognition.RecognizedWordUnit> les objets sont obtenus à partir de la <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur le <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(ReadOnlyCollection<RecognizedWordUnit> words, WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public RecognizedWordUnit (string text, float confidence, string pronunciation, string lexicalForm, System.Speech.Recognition.DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string text, float32 confidence, string pronunciation, string lexicalForm, valuetype System.Speech.Recognition.DisplayAttributes displayAttributes, valuetype System.TimeSpan audioPosition, valuetype System.TimeSpan audioDuration) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognizedWordUnit.#ctor(System.String,System.Single,System.String,System.String,System.Speech.Recognition.DisplayAttributes,System.TimeSpan,System.TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; RecognizedWordUnit(System::String ^ text, float confidence, System::String ^ pronunciation, System::String ^ lexicalForm, System::Speech::Recognition::DisplayAttributes displayAttributes, TimeSpan audioPosition, TimeSpan audioDuration);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.RecognizedWordUnit : string * single * string * string * System.Speech.Recognition.DisplayAttributes * TimeSpan * TimeSpan -&gt; System.Speech.Recognition.RecognizedWordUnit" Usage="new System.Speech.Recognition.RecognizedWordUnit (text, confidence, pronunciation, lexicalForm, displayAttributes, audioPosition, audioDuration)" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="text" Type="System.String" />
        <Parameter Name="confidence" Type="System.Single" />
        <Parameter Name="pronunciation" Type="System.String" />
        <Parameter Name="lexicalForm" Type="System.String" />
        <Parameter Name="displayAttributes" Type="System.Speech.Recognition.DisplayAttributes" />
        <Parameter Name="audioPosition" Type="System.TimeSpan" />
        <Parameter Name="audioDuration" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="text">Texte normalisé pour un mot reconnu.  Cette valeur peut être <see langword="null" />, "" ou <see cref="F:System.String.Empty" />.</param>
        <param name="confidence">Valeur <see langword="float" /> allant de 0 à 1 qui indique la certitude de la reconnaissance du mot.</param>
        <param name="pronunciation">Orthographe phonétique d'un mot reconnu.  Cette valeur peut être <see langword="null" />, "" ou <see cref="F:System.String.Empty" />.</param>
        <param name="lexicalForm">Texte non normalisé pour un mot reconnu.  Cet argument est requis et peut ne pas être <see langword="null" />, "", ou <see cref="F:System.String.Empty" />.</param>
        <param name="displayAttributes">Définit l'utilisation de l'espace blanc pour l'affichage des mots identifiés.</param>
        <param name="audioPosition">Emplacement du mot reconnu dans le flux d'entrée audio.  Cette valeur peut être <see cref="F:System.TimeSpan.Zero" />.</param>
        <param name="audioDuration">Longueur de l'entrée audio correspondant au mot reconnu.  Cette valeur peut être <see cref="F:System.TimeSpan.Zero" />.</param>
        <summary>Initialise une nouvelle instance de la classe <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Si `text` ou `pronunciation` sont `null`, « », ou <xref:System.String.Empty> et <xref:System.Speech.Recognition.RecognizedWordUnit> est utilisé dans une opération de reconnaissance, le moteur de reconnaissance générera les valeurs appropriées dans toute sortie <xref:System.Speech.Recognition.RecognizedWordUnit> instance.  
  
 Diriger la construction de <xref:System.Speech.Recognition.RecognizedWordUnit> instances est généralement utilisé uniquement pour l’émulation des opérations de reconnaissance à l’aide de la <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A> ou <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A> méthodes de la <xref:System.Speech.Recognition.SpeechRecognitionEngine> classe et le <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> ou <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> méthodes de la <xref:System.Speech.Recognition.SpeechRecognizer> classe.  
  
 Pour les applications réelles, ne construisez pas de directement <xref:System.Speech.Recognition.RecognizedWordUnit>, plutôt l’obtenir via le <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur le <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
   
  
## Examples  
 L’exemple suivant est un test quelque peu fictif d’émulation, où nouveaux mots sont générés à partir de l’entrée passés à l’émulateur et ensuite vérifiés.  
  
```csharp  
private void _emulateAndVerify_Click(object sender, EventArgs e)   
{  
  char[] delimiterChars = { ' ', ',', '.', ':', ';', '\t' };  
  string text = _emulateTextBox.Text;  
  string[] words = text.Split(delimiterChars);  
  
  RecognizedWordUnit[] InputWordUnits = new RecognizedWordUnit[words.Length];  
  for (int i = 0; i < words.Length; i++)   
  {  
    InputWordUnits[i] = new RecognizedWordUnit(  
        "",   
        0,   
        "",  
        words[i].ToLower(),   
        DisplayAttributes.OneTrailingSpace,   
        new TimeSpan(),   
        new TimeSpan());  
  }  
  
  RecognitionResult rec = _recognizer.EmulateRecognize(  
        InputWordUnits,   
        System.Globalization.CompareOptions.IgnoreCase);  
  if (rec == null)   
  {  
    MessageBox.Show(String.Format("Recognition emulation for {0} failed.\n", text));  
  }   
  else if (InputWordUnits.Length != rec.Words.Count)   
  {  
    MessageBox.Show(  
       String.Format("Length mismatch: Input was {0} words, Recognition has {1} words.\n}"));  
  }   
  else   
  {  
    for (int i = 0; i < InputWordUnits.Length; i++)   
    {  
  
      if (rec.Words[i].LexicalForm.ToLower() != InputWordUnits[i].LexicalForm.ToLower())   
      {  
        MessageBox.Show(  
          String.Format("Input word {0} \"{1}\" not found. Recognition output is {2}",  
          i, InputWordUnits[i].LexicalForm, rec.Words[i].LexicalForm));  
        continue;  
      }  
    }  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Confidence">
      <MemberSignature Language="C#" Value="public float Confidence { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance float32 Confidence" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Confidence As Single" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property float Confidence { float get(); };" />
      <MemberSignature Language="F#" Value="member this.Confidence : single" Usage="System.Speech.Recognition.RecognizedWordUnit.Confidence" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Single</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient une valeur, assignée par le module de reconnaissance, qui représente la probabilité qu'un mot reconnu corresponde à une entrée donnée.</summary>
        <value>Mesure relative de la certitude de la reconnaissance correcte d'un mot. La valeur va de 0,0 à 1,0, correspondant respectivement à la confiance faible et élevée.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Scores de confiance n’indiquent pas la probabilité absolue qu’un mot a été correctement reconnu. Au lieu de cela, les scores de confiance fournissent un mécanisme pour comparer la précision relative de plusieurs variantes de reconnaissance pour une entrée donnée. Cela facilite le retour du résultat de reconnaissance plus précis. Par exemple, si un mot reconnu a un score de confiance de 0,8, cela ne signifie pas que le mot a une 80 % de chance d’être la correspondance correcte pour l’entrée.  Cela signifie que le mot est plus susceptible d’être la correspondance correcte pour l’entrée à d’autres résultats qui ont confiance scores inférieure à 0,8.  
  
 Un score de confiance en soi n’est pas significatif, sauf si vous avez d’autres résultats à comparer à partir de la même opération de reconnaissance ou reconnaissances précédentes de la même entrée.  
  
 Les valeurs retournées par <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> sont relatif et uniques pour chaque moteur de reconnaissance. Il n’existe aucune définition de comparer des valeurs de confiance entre deux moteurs de reconnaissance différents, ni comment le <xref:System.Speech.Recognition.RecognizedWordUnit.Confidence%2A> d’individu <xref:System.Speech.Recognition.RecognizedWordUnit> des objets qui définissent le <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> d’un <xref:System.Speech.Recognition.RecognizedPhrase>.  
  
 Un moteur de reconnaissance vocale peut affecter un score de confiance faible pour l’entrée parlée pour différentes raisons, notamment des interférences d’arrière-plan, inarticulate vocale, ou mots imprévues ou séquences de word. Si votre application utilise un <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance, vous pouvez modifier le niveau de confiance à quels vocale entrée est acceptée ou rejetée avec l’un de le <xref:System.Speech.Recognition.SpeechRecognitionEngine.UpdateRecognizerSetting%2A> méthodes. Seuils de niveau de confiance pour le module de reconnaissance partagé, géré par <xref:System.Speech.Recognition.SpeechRecognizer>, sont associés à un profil utilisateur et stocké dans le Registre Windows. Les applications ne doivent pas écrire de modifications dans le Registre pour les propriétés du module de reconnaissance partagée.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="DisplayAttributes">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.DisplayAttributes DisplayAttributes { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.DisplayAttributes DisplayAttributes" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property DisplayAttributes As DisplayAttributes" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::DisplayAttributes DisplayAttributes { System::Speech::Recognition::DisplayAttributes get(); };" />
      <MemberSignature Language="F#" Value="member this.DisplayAttributes : System.Speech.Recognition.DisplayAttributes" Usage="System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.DisplayAttributes</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient les informations de mise en forme utilisée pour créer la sortie de texte de l'instance actuelle de <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />.</summary>
        <value>Spécifie l'utilisation de l'espace blanc dans l'affichage du contenu d'un objet <see cref="T:System.Speech.Recognition.RecognizedWordUnit" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Le <xref:System.Speech.Recognition.DisplayAttributes> objet retourné par la <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> propriété spécifie les espaces de début et de fin pour être utilisé avec un mot donné, le cas échéant.  
  
 Pour plus d’informations sur la façon d’utiliser ces informations de mise en forme, consultez la <xref:System.Speech.Recognition.DisplayAttributes> énumération.  
  
   
  
## Examples  
 L’exemple suivant montre une routine d’utilitaire (`stringFromWordArray`) qui génère une chaîne qui est mise en forme de trois manières : lexicalement (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisé (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>), ou phonétiquement (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). La sortie de texte est obtenue à partir de la <xref:System.Speech.Recognition.RecognizedWordUnit.DisplayAttributes%2A> propriété sur un <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> de <xref:System.Speech.Recognition.RecognizedWordUnit> objets obtenu à partir de la <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur un <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
        ReadOnlyCollection<RecognizedWordUnit> words,   
        WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }  
    else if (type == WordType.Pronunciation)   
    {  
       wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
         String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="LexicalForm">
      <MemberSignature Language="C#" Value="public string LexicalForm { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string LexicalForm" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property LexicalForm As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ LexicalForm { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.LexicalForm : string" Usage="System.Speech.Recognition.RecognizedWordUnit.LexicalForm" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient le texte non normalisé d'un mot reconnu.</summary>
        <value>Retourne une <see cref="T:System.String" /> contenant le texte d'un mot reconnu, sans aucune normalisation.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dans la plupart des cas, les valeurs retournées par <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> et <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> sont identiques. Toutefois, moteurs de reconnaissance peuvent utiliser la normalisation de reconnaissance vocale pour retourner les représentations textuelles plus conviviale ou parties de l’entrée audio.  
  
 Normalisation de reconnaissance vocale est l’utilisation de constructions particulières ou des symboles pour exprimer la reconnaissance vocale dans l’écriture. Par exemple, la normalisation peut remplacer les mots « un dollar et seize cents » avec « $1.16 » dans le texte de sortie.  
  
   
  
## Examples  
 L’exemple suivant montre une routine d’utilitaire qui génère du texte dans un des trois formats : lexicale (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisé (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>) et phonétique (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). La sortie de texte est obtenue à partir d’un <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> de <xref:System.Speech.Recognition.RecognizedWordUnit> objets obtenu à partir de la <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur le <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
         ReadOnlyCollection<RecognizedWordUnit> words,   
         WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)  
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)  
    {  
    wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Pronunciation">
      <MemberSignature Language="C#" Value="public string Pronunciation { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Pronunciation" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Pronunciation As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Pronunciation { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Pronunciation : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Pronunciation" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient l'orthographe phonétique d'un mot reconnu.</summary>
        <value>Chaîne de caractères d'un alphabet phonétique pris en charge, tel que l'alphabet phonétique international (IPA) ou UPS (Universal Phone Set).</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Le contenu de <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A> indiquer quels prononciation du moteur de reconnaissance vocale utilisé pour faire correspondre la saisie vocale à un de ses chargé <xref:System.Speech.Recognition.Grammar> objets. Prononciations personnalisées peuvent être définies dans un lexique interne du moteur de reconnaissance vocale, dans un document de lexique est lié à partir d’une grammaire de reconnaissance dans un chargé <xref:System.Speech.Recognition.Grammar> objet ou inline dans une syntaxe de reconnaissance dans un chargé <xref:System.Speech.Recognition.Grammar> objet. Un module de reconnaissance vocale peut également créer des prononciations des rares mots dont prononciations ne sont pas définies dans un lexique ou de la grammaire à laquelle le moteur de reconnaissance vocale a actuellement accès.  
  
 De polices Unicode basé sur Windows, tels que Courier New, prennent en charge l’affichage de chaînes du fichier IPA. Pour plus d’informations, consultez [Alphabet phonétique International](http://go.microsoft.com/fwlink/?LinkId=58363).  
  
   
  
## Examples  
 L’exemple suivant montre une routine d’utilitaire qui génère une chaîne avec un des trois formats possibles : lexicale (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisé (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>) et phonétique (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). La sortie de texte est obtenue à partir d’un <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> de <xref:System.Speech.Recognition.RecognizedWordUnit> objets obtenu à partir de la <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur le <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
          String.Format("[0}: is not a valid input", type));  
    }  
    // Use display attribute  
  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.DisplayAttributes" />
      </Docs>
    </Member>
    <Member MemberName="Text">
      <MemberSignature Language="C#" Value="public string Text { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance string Text" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Text As String" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::String ^ Text { System::String ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Text : string" Usage="System.Speech.Recognition.RecognizedWordUnit.Text" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient le texte normalisé d'un mot reconnu.</summary>
        <value>Chaîne qui contient la sortie de texte normalisée pour un mot entré donné.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Dans la plupart des cas, les valeurs retournées par <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A> et <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A> seront identiques. Toutefois, moteurs de reconnaissance peuvent utiliser la normalisation de reconnaissance vocale pour retourner les représentations textuelles plus conviviale ou parties de l’entrée audio.  
  
 Normalisation de reconnaissance vocale est l’utilisation de constructions particulières ou des symboles pour exprimer la reconnaissance vocale dans l’écriture. Par exemple, la normalisation peut remplacer les mots « un dollar et seize cents » avec « $1.16 » dans le texte de sortie.  
  
   
  
## Examples  
 L’exemple suivant montre une routine d’utilitaire qui génère une chaîne dans un des trois formats : lexicale (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.LexicalForm%2A>), normalisé (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Text%2A>) et phonétique (à l’aide de <xref:System.Speech.Recognition.RecognizedWordUnit.Pronunciation%2A>). La sortie de texte est obtenue à partir d’un <xref:System.Collections.ObjectModel.ReadOnlyCollection%601> de <xref:System.Speech.Recognition.RecognizedWordUnit> objets obtenu à partir de la <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> propriété sur le <xref:System.Speech.Recognition.RecognizedPhrase> objet.  
  
```csharp  
  
internal enum WordType   
{  
  Text,  
  Normalized = Text,  
  Lexical,  
  Pronunciation  
}  
```  
  
```csharp  
internal static string stringFromWordArray(  
          ReadOnlyCollection<RecognizedWordUnit> words,   
          WordType type)   
{  
  string text = "";  
  foreach (RecognizedWordUnit word in words)   
  {  
    string wordText = "";  
    if (type == WordType.Text || type == WordType.Normalized)   
    {  
      wordText = word.Text;  
    }   
    else if (type == WordType.Lexical)   
    {  
      wordText = word.LexicalForm;  
    }   
    else if (type == WordType.Pronunciation)   
    {  
      wordText = word.Pronunciation;  
    }   
    else   
    {  
      throw new InvalidEnumArgumentException(  
           String.Format("[0}: is not a valid input", type));  
    }  
  
    // Use display attribute  
    if ((word.DisplayAttributes & DisplayAttributes.OneTrailingSpace) != 0)   
    {  
      wordText += " ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.TwoTrailingSpaces) != 0)   
    {  
      wordText += "  ";  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ConsumeLeadingSpaces) != 0)   
    {  
      wordText = wordText.TrimStart();  
    }  
    if ((word.DisplayAttributes & DisplayAttributes.ZeroTrailingSpaces) != 0)   
    {  
      wordText = wordText.TrimEnd();  
    }  
  
    text += wordText;  
  
  }  
  return text;  
}  
```  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>