<Type Name="RecognizerUpdateReachedEventArgs" FullName="System.Speech.Recognition.RecognizerUpdateReachedEventArgs">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="77798094a96becd337441519d667f9c64129b168" />
    <Meta Name="ms.sourcegitcommit" Value="434f60616a9793fa8436744549fc856e94f7a648" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="fr-FR" />
    <Meta Name="ms.lasthandoff" Value="08/25/2018" />
    <Meta Name="ms.locfileid" Value="39872918" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class RecognizerUpdateReachedEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit RecognizerUpdateReachedEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizerUpdateReachedEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizerUpdateReachedEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type RecognizerUpdateReachedEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Retourne des données d'un événement <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" /> ou <see cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `RecognizerUpdateReached` les événements fournissent un mécanisme pour l’interruption d’un module de reconnaissance vocale pour appliquer les modifications atomiques et synchrones, telles que le chargement et déchargement des grammaires.  
  
 Si votre application utilise un <xref:System.Speech.Recognition.SpeechRecognitionEngine> pour gérer la reconnaissance de l’instance, il peut utiliser une de le <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A?displayProperty=nameWithType> méthodes pour demander que le moteur met en pause pour recevoir une mise à jour. Le <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance déclenche un <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> événement lorsqu’il est prêt pour la mise à jour.  
  
 Pendant un <xref:System.Speech.Recognition.SpeechRecognitionEngine> instance est suspendue, vous pouvez charger, décharger, activer et désactiver <xref:System.Speech.Recognition.Grammar> objets et modifier des valeurs pour le <xref:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout%2A>, <xref:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout%2A>, et <xref:System.Speech.Recognition.SpeechRecognitionEngine.EndSilenceTimeout%2A> propriétés.  
  
 Si votre application utilise un <xref:System.Speech.Recognition.SpeechRecognizer> pour gérer la reconnaissance de l’instance, il peut utiliser une de le <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A?displayProperty=nameWithType> méthodes pour demander que le moteur met en pause pour recevoir une mise à jour. Le <xref:System.Speech.Recognition.SpeechRecognizer> instance déclenche un <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached?displayProperty=nameWithType> événement lorsqu’il est prêt pour la mise à jour.  
  
 Pendant un <xref:System.Speech.Recognition.SpeechRecognizer> instance est suspendue, vous pouvez charger, décharger, activer et désactiver <xref:System.Speech.Recognition.Grammar> objets.  
  
 Lors de la gestion <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> et <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached?displayProperty=nameWithType> événements, un moteur de reconnaissance s’interrompt jusqu'à ce que le Gestionnaire d’événements retourne.  
  
 <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> dérive de <xref:System.EventArgs>.  
  
   
  
## Examples  
 L’exemple suivant montre une application console qui charge et décharge <xref:System.Speech.Recognition.Grammar> objets. L’application utilise le <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> méthode pour demander le moteur de reconnaissance vocale en pause afin qu’elle peut recevoir une mise à jour. L’application, puis charge ou décharge un <xref:System.Speech.Recognition.Grammar> objet.  
  
 À chaque mise à jour, un gestionnaire pour <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> d’événement écrit le nom et l’état d’actuellement chargés <xref:System.Speech.Recognition.Grammar> objets dans la console. Comme les grammaires sont chargées et déchargées, l’application reconnaît tout d’abord les noms des animaux de batterie de serveurs, puis les noms des animaux de batterie de serveurs et les noms des fruits, puis uniquement les noms de fruits.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the Farm grammar.  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start asynchronous, continuous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous, continuous recognition");  
        Console.WriteLine("  Farm grammar is loaded and enabled.");  
  
        // Pause to recognize farm animals.  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Request an update and load the Fruit grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Thread.Sleep(7000);  
  
        // Request an update and unload the Farm grammar.  
        recognizer.RequestRecognizerUpdate();  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  {0} grammar is loaded and {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient la position audio associée à l'événement.</summary>
        <value>Retourne l’emplacement dans la mémoire tampon vocale d’un <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> ou un <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> quand il s’interrompt et déclenche une <c>RecognizerUpdateReached</c> événement.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Les applications peuvent utiliser l’emplacement indiqué par <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.AudioPosition%2A> pour accéder à l’entrée audio qui s’est produite pendant que le moteur de reconnaissance a été suspendu.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="UserToken">
      <MemberSignature Language="C#" Value="public object UserToken { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance object UserToken" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property UserToken As Object" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Object ^ UserToken { System::Object ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.UserToken : obj" Usage="System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Object</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtient le <c>UserToken</c> passé au système quand une application appelle <see cref="Overload:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" /> ou <see cref="Overload:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />.</summary>
        <value>Retourne un objet qui contienne le <c>UserToken</c>.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Une application spécifie un `UserToken` quand il demande la génération d’un `RecognizerUpdateReached` événement en appelant une de la <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A?displayProperty=nameWithType> ou <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A?displayProperty=nameWithType> méthodes qui prennent un `userToken` paramètre.  
  
   
  
## Examples  
 L’exemple suivant montre une application console qui charge et décharge <xref:System.Speech.Recognition.Grammar> objets. L’application utilise le <xref:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate%2A> méthode pour demander le moteur de reconnaissance vocale en pause afin qu’elle peut recevoir une mise à jour. La méthode passe un <xref:System.String> de l’objet pour le `userToken` paramètre qui décrit ce que l’application reconnaît après la mise à jour. L’application, puis charge ou décharge un <xref:System.Speech.Recognition.Grammar> objet.  
  
 À chaque mise à jour, un gestionnaire pour <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached?displayProperty=nameWithType> événement écrit le contenu de `userToken` à la console. Comme les grammaires sont chargées et déchargées, l’application reconnaît tout d’abord les noms des animaux de batterie de serveurs, puis les noms des animaux de batterie de serveurs et les noms des fruits, puis uniquement les noms de fruits.  
  
```  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      using (recognizer = new SpeechRecognitionEngine(  
        new System.Globalization.CultureInfo("en-US")))  
      {  
        recognizer.SetInputToDefaultAudioDevice();  
  
        // Create the first grammar - Farm.  
        Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
        GrammarBuilder farm = new GrammarBuilder(animals);  
        Grammar farmAnimals = new Grammar(farm);  
        farmAnimals.Name = "Farm";  
  
        // Create the second grammar - Fruit.  
        Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
        GrammarBuilder favorite = new GrammarBuilder(fruit);  
        Grammar favoriteFruit = new Grammar(favorite);  
        favoriteFruit.Name = "Fruit";  
  
        // Attach event handlers.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.RecognizerUpdateReached +=  
          new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
        recognizer.SpeechRecognitionRejected +=  
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the farmAnimals grammar  
        recognizer.LoadGrammar(farmAnimals);  
  
        // Start continuous, asynchronous recognition.  
        recognizer.RecognizeAsync(RecognizeMode.Multiple);  
        Console.WriteLine("Starting asynchronous recognition...");  
        Console.WriteLine("  Farm animals will now be recognized.");  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Load the Fruit grammar.  
        string activeGrammars = "Farm animals and fruits will now be recognized.";  
        recognizer.RequestRecognizerUpdate(activeGrammars);  
        recognizer.LoadGrammarAsync(favoriteFruit);  
        Console.WriteLine();  
        Thread.Sleep(7000);  
        Console.WriteLine();  
  
        // Unload the Farm grammar.  
        string onlyFruit = "Only fruits will now be recognized.";  
        recognizer.RequestRecognizerUpdate(onlyFruit);  
        recognizer.UnloadGrammar(farmAnimals);  
        Thread.Sleep(7000);  
      }  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // At the update, describe what the application will recognize next.  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine("  Update reached: " + e.UserToken);  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("    Speech recognized: " + e.Result.Text);  
    }  
  
    // Write a message to the console when recognition fails.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("    Recognition attempt failed");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerUpdateReached" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
  </Members>
</Type>